@article{agrawal2017near,
  title={Near-optimal regret bounds for thompson sampling},
  author={Agrawal, Shipra and Goyal, Navin},
  journal={Journal of the ACM},
  volume={64},
  number={5},
  pages={1--24},
  year={2017}
}

@inproceedings{audibert2009minimax,
  title={Minimax policies for adversarial and stochastic bandits},
  author={Audibert, Jean-Yves and Bubeck, S{\'e}bastien},
  booktitle={COLT},
  year={2009}
}

@article{auer2002finite,
  title={Finite-time analysis of the multiarmed bandit problem},
  author={Auer, Peter and Cesa-Bianchi, Nicolo and Fischer, Paul},
  journal={Machine learning},
  volume={47},
  number={2-3},
  pages={235--256},
  year={2002}
}

@article{audibert2009exploration,
  title={Exploration--exploitation tradeoff using variance estimates in multi-armed bandits},
  author={Audibert, Jean-Yves and Munos, R{\'e}mi and Szepesv{\'a}ri, Csaba},
  journal={Theoretical Computer Science},
  volume={410},
  number={19},
  pages={1876--1902},
  year={2009}
}

@article{agrawal2019mnl,
  title={MNL-bandit: A dynamic learning approach to assortment selection},
  author={Agrawal, Shipra and Avadhanula, Vashist and Goyal, Vineet and Zeevi, Assaf},
  journal={Operations Research},
  volume={67},
  number={5},
  pages={1453--1485},
  year={2019}
}

@inproceedings{audibert2010best,
  title={Best arm identification in multi-armed bandits},
  author={Audibert, Jean-Yves and Bubeck, S{\'e}bastien},
  booktitle={COLT},
  year={2010}
}

@inproceedings{karnin2013almost,
  title={Almost optimal exploration in multi-armed bandits},
  author={Karnin, Zohar and Koren, Tomer and Somekh, Oren},
  booktitle={ICML},
  pages={1238--1246},
  year={2013}
}

@inproceedings{jamieson2014lil,
  title={lil’ucb: An optimal exploration algorithm for multi-armed bandits},
  author={Jamieson, Kevin and Malloy, Matthew and Nowak, Robert and Bubeck, S{\'e}bastien},
  booktitle={COLT},
  pages={423--439},
  year={2014}
}

@article{gupta2018exploiting,
  title={Exploiting correlation in finite-armed structured bandits},
  author={Gupta, Samarth and Chaudhari, Shreyas and Joshi, Gauri and Ya{\u{g}}an, Osman},
  journal={arXiv preprint arXiv:1810.08164},
  year={2018}
}

@article{Gupta2019MultiArmedBW,
  title={Multi-Armed Bandits with Correlated Arms},
  author={Samarth Gupta and Shreyas Chaudhari and Gauri Joshi and Osman Yağan},
  journal={ArXiv},
  year={2019},
  volume={abs/1911.03959}
}

@article{feraud2018decentralized,
  title={Decentralized Exploration in Multi-Armed Bandits},
  author={F{\'e}raud, Rapha{\"e}l and Alami, R{\'e}da and Laroche, Romain},
  journal={arXiv preprint arXiv:1811.07763},
  year={2018}
}

@inproceedings{xu2017fully,
  title={Fully adaptive algorithm for pure exploration in linear bandits},
  author={Xu, Liyuan and Honda, Junya and Sugiyama, Masashi},
  booktitle={AISTATS},
  year={2017}
}

@article{DBLP:journals/corr/AgrawalAGZ17a,
  author    = {Shipra Agrawal and
               Vashist Avadhanula and
               Vineet Goyal and
               Assaf Zeevi},
  title     = {MNL-Bandit: {A} Dynamic Learning Approach to Assortment Selection},
  journal   = {CoRR},
  volume    = {abs/1706.03880},
  year      = {2017}
}

@article{DBLP:journals/corr/AgrawalAGZ17,
  author    = {Shipra Agrawal and
               Vashist Avadhanula and
               Vineet Goyal and
               Assaf Zeevi},
  title     = {Thompson Sampling for the MNL-Bandit},
  journal   = {CoRR},
  volume    = {abs/1706.00977},
  year      = {2017}
}
